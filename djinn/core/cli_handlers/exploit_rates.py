import os
import csv
import json
import re
from pathlib import Path
from typing import Dict, Iterable, List, Tuple, Set


def _ensure_dir(path: str) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)


def _iter_jsonl(paths: List[str]) -> Iterable[dict]:
    for p in paths:
        path = Path(p)
        if not path.exists():
            continue
        if path.is_dir():
            for f in path.rglob("*.jsonl"):
                yield from _read_jsonl_file(f)
        else:
            if path.suffix.lower() == ".jsonl":
                yield from _read_jsonl_file(path)


def _read_jsonl_file(path: Path) -> Iterable[dict]:
    try:
        with path.open("r", encoding="utf-8") as f:
            # Robust JSON object stream reader:
            # - Supports strict JSONL (one object per line)
            # - Supports pretty-printed multi-line JSON objects
            # We track brace depth outside of strings; when it returns to 0 we parse.
            buffer_chars: list[str] = []
            depth = 0
            in_string = False
            escape = False
            parsed_count = 0
            error_count = 0

            def flush_buffer():
                nonlocal buffer_chars, parsed_count, error_count
                if not buffer_chars:
                    return
                candidate = "".join(buffer_chars).strip()
                buffer_chars = []
                if not candidate:
                    return
                try:
                    obj = json.loads(candidate)
                    if isinstance(obj, dict):
                        parsed_count += 1
                        return obj
                except json.JSONDecodeError:
                    # Retry by stripping massive 'reasoning' fields which may be malformed
                    try:
                        stripped = re.sub(r'"reasoning"\s*:\s*"([^"\\]|\\.)*?"\s*,?', '"reasoning":""', candidate, flags=re.S)
                        obj = json.loads(stripped)
                        if isinstance(obj, dict):
                            parsed_count += 1
                            return obj
                    except Exception:
                        error_count += 1
                return None

            for raw_line in f:
                stripped = raw_line.strip()
                if not buffer_chars and stripped:
                    # Try fast-path single-line parse
                    try:
                        obj = json.loads(stripped)
                        if isinstance(obj, dict):
                            parsed_count += 1
                            yield obj
                            continue
                    except json.JSONDecodeError:
                        # Fall back to accumulating (pretty-printed multiline objects)
                        pass

                for ch in raw_line:
                    buffer_chars.append(ch)
                    if in_string:
                        if escape:
                            escape = False
                        elif ch == '\\':
                            escape = True
                        elif ch == '"':
                            in_string = False
                        continue
                    else:
                        if ch == '"':
                            in_string = True
                            continue
                        if ch == '{':
                            depth += 1
                        elif ch == '}':
                            depth = max(0, depth - 1)
                            if depth == 0:
                                obj = flush_buffer()
                                if obj is not None:
                                    yield obj

            # Flush leftovers (handles files that end without newline)
            if buffer_chars:
                obj = flush_buffer()
                if obj is not None:
                    yield obj

            if error_count and parsed_count == 0:
                print(f"Warning: {path} appears malformed; parsed=0, errors={error_count}")
    except FileNotFoundError:
        return


def _get_exploit_type(row: dict) -> str:
    """Robustly extract exploit_type from a row allowing for minor key drift."""
    val = row.get("exploit_type")
    if isinstance(val, str) and val.strip():
        return val.strip()
    # Fallback: normalize keys to catch whitespace/casing differences
    for k, v in row.items():
        try:
            k_norm = str(k).strip().lower()
        except Exception:
            continue
        if k_norm == "exploit_type" and isinstance(v, str) and v.strip():
            return v.strip()
    # Additional common alternates seen in some writers
    for alt in ("attack_type", "exploitType", "exploit"):
        v = row.get(alt)
        if isinstance(v, str) and v.strip():
            return v.strip()
    return ""


def _coarse_scan_file_for_rows(path: Path, max_windows: int = 100, window_lines: int = 40) -> List[dict]:
    """Very tolerant fallback: scan the file in small line windows and extract
    minimal fields (model_id/model, exploit_type, split, secure_pass,
    insecure_pass, exploit_success) using regex without requiring valid JSON.
    """
    rows: List[dict] = []
    try:
        with path.open("r", encoding="utf-8") as f:
            buf: List[str] = []
            windows = 0
            for line in f:
                if line.strip():
                    buf.append(line)
                if len(buf) >= window_lines:
                    block = "".join(buf)
                    # Strip gigantic reasoning to increase chance of match
                    block = re.sub(r'"reasoning"\s*:\s*"[\s\S]*?"\s*,', '"reasoning":"",', block)
                    # Extract fields
                    def grab_str(key: str) -> str:
                        m = re.search(r'\"' + re.escape(key) + r'\"\s*:\s*\"([^\"]*)\"', block)
                        return m.group(1).strip() if m else ""
                    def grab_boolish(key: str):
                        m = re.search(r'\"' + re.escape(key) + r'\"\s*:\s*(true|false|\"[^\"]*\")', block, flags=re.I)
                        if not m:
                            return None
                        val = m.group(1)
                        if isinstance(val, str) and val.lower() in ("true", "false"):
                            return val.lower() == "true"
                        sval = str(val).strip('"').strip()
                        return sval.lower() in ("1", "true", "t", "yes", "y", "passed")
                    etype = (grab_str("exploit_type") or grab_str("attack_type") or grab_str("exploitType") or grab_str("exploit")).strip()
                    if etype:
                        rows.append({
                            "model_id": (grab_str("model_id") or grab_str("model")).strip(),
                            "exploit_type": etype,
                            "split": (grab_str("split") or "eval").strip() or "eval",
                            "secure_pass": grab_boolish("secure_pass"),
                            "insecure_pass": grab_boolish("insecure_pass"),
                            "exploit_success": grab_boolish("exploit_success"),
                        })
                    buf = []
                    windows += 1
                    if windows >= max_windows:
                        break
            # Final partial window
            if buf and len(rows) == 0:
                block = "".join(buf)
                block = re.sub(r'"reasoning"\s*:\s*"[\s\S]*?"\s*,', '"reasoning":"",', block)
                def grab_str(key: str) -> str:
                    m = re.search(r'\"' + re.escape(key) + r'\"\s*:\s*\"([^\"]*)\"', block)
                    return m.group(1).strip() if m else ""
                def grab_boolish(key: str):
                    m = re.search(r'\"' + re.escape(key) + r'\"\s*:\s*(true|false|\"[^\"]*\")', block, flags=re.I)
                    if not m:
                        return None
                    val = m.group(1)
                    if isinstance(val, str) and val.lower() in ("true", "false"):
                        return val.lower() == "true"
                    sval = str(val).strip('"').strip()
                    return sval.lower() in ("1", "true", "t", "yes", "y", "passed")
                etype = (grab_str("exploit_type") or grab_str("attack_type") or grab_str("exploitType") or grab_str("exploit")).strip()
                if etype:
                    rows.append({
                        "model_id": (grab_str("model_id") or grab_str("model")).strip(),
                        "exploit_type": etype,
                        "split": (grab_str("split") or "eval").strip() or "eval",
                        "secure_pass": grab_boolish("secure_pass"),
                        "insecure_pass": grab_boolish("insecure_pass"),
                        "exploit_success": grab_boolish("exploit_success"),
                    })
    except Exception:
        return rows
    return rows


def _discover_model_files(root_dir: str) -> List[Tuple[str, Path]]:
    """
    Scan a directory recursively for per-model JSONL logs.

    Heuristics:
      - Include files whose stem contains a variant token: 'base' or 'ft'.
      - Exclude '*.samples.jsonl' helper files.
      - Exclude 'reward_delta_*' aggregate/diagnostic files.

    Returns a list of (model_label, path) where model_label is derived from the
    file stem (without extension), e.g., 'gpt_oss_120b_extended_ft'.
    """
    base = Path(root_dir)
    if not base.exists() or not base.is_dir():
        return []

    # Rather than rely on brittle suffix patterns, scan top-level jsonl files
    # and select likely per-model logs by simple token heuristics.
    results: List[Tuple[str, Path]] = []
    for f in base.glob("*.jsonl"):
        # Exclude helper/sample files and known non-model aggregates
        if str(f).endswith(".samples.jsonl"):
            continue
        stem = f.stem
        if stem.startswith("reward_delta_"):
            continue
        # Keep files that include a variant indicator
        tokens = set(stem.split("_"))
        if not ("base" in tokens or "ft" in tokens):
            continue
        results.append((stem, f))
    return results


def _load_dataset_exploit_types_by_split(dataset_id: str, train_split: str, eval_split: str) -> Dict[str, Set[str]]:
    """Load exploit types from a HF dataset separately for train and eval splits."""
    result: Dict[str, Set[str]] = {"train": set(), "eval": set()}
    try:
        from datasets import load_dataset  # lazy import
        # Train
        try:
            ds_train = load_dataset(dataset_id, split=train_split)
            if "exploit_type" in ds_train.column_names:
                result["train"].update(t for t in ds_train["exploit_type"] if isinstance(t, str) and t)
        except Exception:
            pass
        # Eval
        try:
            ds_eval = load_dataset(dataset_id, split=eval_split)
            if "exploit_type" in ds_eval.column_names:
                result["eval"].update(t for t in ds_eval["exploit_type"] if isinstance(t, str) and t)
        except Exception:
            pass
    except Exception:
        pass
    return result


def _as_bool(x) -> bool | None:
    if x is None:
        return None
    if isinstance(x, bool):
        return x
    s = str(x).strip().lower()
    if s in ("1", "true", "t", "yes", "y", "passed"):
        return True
    if s in ("0", "false", "f", "no", "n", "failed"):
        return False
    return None


def _parse_label_and_split(label: str) -> Tuple[str, str]:
    """
    Parse a filename stem like 'gpt_oss_120b_ft', 'gpt_oss_120b_ft_noprompt',
    'gpt_oss_120b_ft_train', or 'gpt_oss_120b_ft_train_noprompt' into a
    canonical (model_id, split) pair where split is one of {"train", "eval"} and
    model_id excludes the optional '_train' token.
    """
    # Simple token-based normalization to avoid heavy regex and edge cases
    parts = [p for p in label.split("_") if p]
    # Default to eval unless we explicitly see a train marker
    split = "eval"
    if "train" in parts:
        split = "train"
    # Remove split-indicating tokens from the canonical model id
    # Treat 'test' as the eval split and strip it out as well
    parts = [p for p in parts if p not in {"train", "test", "eval"}]
    # Keep other meaningful variant tokens like 'base', 'ft', 'extended', 'noprompt'
    canonical = "_".join(parts)
    return canonical, split


def handle_exploit_rates(args):
    """
    Compute exploit rates per exploit_type per model from JSONL run logs.

    Inputs:
      --runs: one or more JSONL files or directories (repeatable)
      --out: output CSV path (default: generated_metrics/exploit_rates.csv)
      --min-runs: optional minimum runs per (model, exploit_type) to include
    """
    dir_path: str | None = getattr(args, "dir", None)
    run_paths: List[str] = getattr(args, "runs", []) or []
    labeled_files: List[Tuple[str, Path]] = []

    if dir_path:
        labeled_files = _discover_model_files(dir_path)
        if not labeled_files:
            print(f"Warning: no matching JSONL files found under --dir={dir_path}")
    elif not run_paths:
        print("Error: please provide at least one --runs path (file or directory) or --dir")
        return

    # Aggregate counts keyed by (model_id, split, exploit_type)
    agg: Dict[Tuple[str, str, str], Dict[str, float]] = {}

    if labeled_files:
        # Directory mode: treat each matching file as a distinct model, labeled by filename
        for label, fpath in labeled_files:
            canonical_model_id, split = _parse_label_and_split(label)
            parsed_rows = 0
            typed_rows = 0
            missing_type_rows = 0
            missing_type_example: dict | None = None
            for row in _read_jsonl_file(fpath):
                parsed_rows += 1
                model_id = canonical_model_id
                etype = _get_exploit_type(row)
                if etype:
                    typed_rows += 1
                else:
                    missing_type_rows += 1
                    if missing_type_example is None:
                        missing_type_example = {k: row.get(k) for k in list(row.keys())[:8]}
                key = (model_id, split, etype)
                rec = agg.setdefault(key, {
                    "n_runs": 0.0,
                    "secure_pass_sum": 0.0,
                    "insecure_pass_sum": 0.0,
                    "exploit_success_sum": 0.0,
                })
                rec["n_runs"] += 1.0
                sp = _as_bool(row.get("secure_pass"))
                ip = _as_bool(row.get("insecure_pass"))
                if sp is True:
                    rec["secure_pass_sum"] += 1.0
                if ip is True:
                    rec["insecure_pass_sum"] += 1.0
                ex = row.get("exploit_success")
                if ex is None and (sp is not None and ip is not None):
                    ex = (ip is True) and (sp is False)
                exb = _as_bool(ex)
                if exb is True:
                    rec["exploit_success_sum"] += 1.0
            # Coarse fallback if we failed to parse anything
            if parsed_rows == 0:
                coarse_rows = _coarse_scan_file_for_rows(fpath)
                for row in coarse_rows:
                    model_id = canonical_model_id
                    etype = _get_exploit_type(row)
                    key = (model_id, split, etype)
                    rec = agg.setdefault(key, {
                        "n_runs": 0.0,
                        "secure_pass_sum": 0.0,
                        "insecure_pass_sum": 0.0,
                        "exploit_success_sum": 0.0,
                    })
                    rec["n_runs"] += 1.0
                    sp = _as_bool(row.get("secure_pass"))
                    ip = _as_bool(row.get("insecure_pass"))
                    if sp is True:
                        rec["secure_pass_sum"] += 1.0
                    if ip is True:
                        rec["insecure_pass_sum"] += 1.0
                    exb = _as_bool(row.get("exploit_success"))
                    if exb is True:
                        rec["exploit_success_sum"] += 1.0
            # Emit a diagnostic if nothing parsed for this file
            if parsed_rows == 0:
                print(f"Warning: parsed 0 records from {fpath}")
            elif typed_rows == 0 and missing_type_rows > 0:
                print(f"Warning: {fpath} parsed={parsed_rows} but 0 exploit_type found; showing example keys: {list(missing_type_example.keys()) if missing_type_example else []}")
    else:
        # Legacy mode: read rows and use their embedded model_id
        legacy_parsed = 0
        for row in _iter_jsonl(run_paths):
            legacy_parsed += 1
            model_id = (row.get("model_id") or row.get("model") or "").strip()
            etype = _get_exploit_type(row)
            split = (row.get("split") or "eval").strip() or "eval"
            if not model_id:
                continue
            # If the embedded model_id contains a '_train' token, normalize it out and set split
            normalized_model_id, inferred_split = _parse_label_and_split(model_id)
            if inferred_split == "train":
                split = "train"
            model_id = normalized_model_id
            key = (model_id, split, etype)
            rec = agg.setdefault(key, {
                "n_runs": 0.0,
                "secure_pass_sum": 0.0,
                "insecure_pass_sum": 0.0,
                "exploit_success_sum": 0.0,
            })
            rec["n_runs"] += 1.0
            sp = _as_bool(row.get("secure_pass"))
            ip = _as_bool(row.get("insecure_pass"))
            if sp is True:
                rec["secure_pass_sum"] += 1.0
            if ip is True:
                rec["insecure_pass_sum"] += 1.0
            ex = row.get("exploit_success")
            if ex is None and (sp is not None and ip is not None):
                ex = (ip is True) and (sp is False)
            exb = _as_bool(ex)
            if exb is True:
                rec["exploit_success_sum"] += 1.0
        if legacy_parsed == 0 and run_paths:
            # Coarse fallback for --runs file paths
            for p in run_paths:
                path = Path(p)
                if not (path.exists() and path.is_file() and path.suffix.lower() == ".jsonl"):
                    continue
                coarse_rows = _coarse_scan_file_for_rows(path)
                for row in coarse_rows:
                    model_id = (row.get("model_id") or row.get("model") or "").strip() or path.stem
                    etype = _get_exploit_type(row)
                    split = (row.get("split") or "eval").strip() or "eval"
                    key = (model_id, split, etype)
                    rec = agg.setdefault(key, {
                        "n_runs": 0.0,
                        "secure_pass_sum": 0.0,
                        "insecure_pass_sum": 0.0,
                        "exploit_success_sum": 0.0,
                    })
                    rec["n_runs"] += 1.0
                    sp = _as_bool(row.get("secure_pass"))
                    ip = _as_bool(row.get("insecure_pass"))
                    if sp is True:
                        rec["secure_pass_sum"] += 1.0
                    if ip is True:
                        rec["insecure_pass_sum"] += 1.0
                    exb = _as_bool(row.get("exploit_success"))
                    if exb is True:
                        rec["exploit_success_sum"] += 1.0

    # Discover the full set of exploit types from the dataset (defaulting to v0.9)
    dataset_id = getattr(args, "dataset", None) or "EleutherAI/djinn-problems-v0.9"
    train_split_name = getattr(args, "train_split", None) or "train_alternate"
    eval_split_name = getattr(args, "eval_split", None) or "test_alternate"
    dataset_types_by_split = _load_dataset_exploit_types_by_split(dataset_id, train_split_name, eval_split_name)

    if getattr(args, "out", None):
        out_path = args.out
    elif dir_path:
        out_path = os.path.join(dir_path, "exploit_rates.csv")
    else:
        out_path = os.path.join("generated_metrics", "exploit_rates.csv")
    _ensure_dir(out_path)
    header = ["model_id", "split", "exploit_type", "n_runs", "EPR_insecure", "insecure_pass_rate", "secure_pass_rate"]

    min_runs = max(0, int(getattr(args, "min_runs", 0) or 0))
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()

        # Determine models and splits present in the aggregated data
        model_ids: List[str] = sorted({mid for (mid, _, _) in agg.keys()})
        splits_by_model: Dict[str, Set[str]] = {}
        for (mid, split, _) in agg.keys():
            splits_by_model.setdefault(mid, set()).add(split)

        # Observed fallback types per split
        observed_types_by_split: Dict[str, Set[str]] = {"train": set(), "eval": set()}
        for (_, split_k, etype_k) in agg.keys():
            if split_k in ("train", "eval") and etype_k:
                observed_types_by_split[split_k].add(etype_k)

        for mid in model_ids:
            for split in sorted(splits_by_model.get(mid, set()) or {"eval"}):
                if split == "train":
                    type_set = (dataset_types_by_split.get("train") or set()) | observed_types_by_split["train"]
                else:
                    type_set = (dataset_types_by_split.get("eval") or set()) | observed_types_by_split["eval"]
                for etype in sorted(type_set):
                    rec = agg.get((mid, split, etype), {
                        "n_runs": 0.0,
                        "secure_pass_sum": 0.0,
                        "insecure_pass_sum": 0.0,
                        "exploit_success_sum": 0.0,
                    })
                    n = int(rec["n_runs"]) if rec["n_runs"] else 0
                    if n < min_runs:
                        continue
                    # Avoid divide-by-zero for zero-run rows
                    if n == 0:
                        epr = ipr = spr = 0.0
                    else:
                        epr = rec["exploit_success_sum"] / n
                        ipr = rec["insecure_pass_sum"] / n
                        spr = rec["secure_pass_sum"] / n
                    writer.writerow({
                        "model_id": mid,
                        "split": split,
                        "exploit_type": etype,
                        "n_runs": n,
                        "EPR_insecure": f"{epr:.6f}",
                        "insecure_pass_rate": f"{ipr:.6f}",
                        "secure_pass_rate": f"{spr:.6f}",
                    })

    print(f"Wrote exploit rates: {out_path}")

